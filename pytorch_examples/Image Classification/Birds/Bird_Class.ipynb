{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/gpiosenka/100-bird-species"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def image_loader(data_dict):\n",
    "    # Load the image using OpenCV\n",
    "    images = []\n",
    "    for filepath in data_dict['filepaths']:\n",
    "        img = cv2.imread(filepath)\n",
    "        images.append(img)\n",
    "    # Convert the image to a tensor\n",
    "    img_tensors = [torch.from_numpy(img) for img in images]\n",
    "\n",
    "    labels = [i for i in train_data['class_id']]\n",
    "\n",
    "    return img_tensors, labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   class id                      filepaths           labels  \\\n0         0  train/ABBOTTS BABBLER/001.jpg  ABBOTTS BABBLER   \n1         0  train/ABBOTTS BABBLER/002.jpg  ABBOTTS BABBLER   \n2         0  train/ABBOTTS BABBLER/003.jpg  ABBOTTS BABBLER   \n3         0  train/ABBOTTS BABBLER/004.jpg  ABBOTTS BABBLER   \n4         0  train/ABBOTTS BABBLER/005.jpg  ABBOTTS BABBLER   \n\n       scientific label data set  \n0  Malacocincla abbotti    train  \n1  Malacocincla abbotti    train  \n2  Malacocincla abbotti    train  \n3  Malacocincla abbotti    train  \n4  Malacocincla abbotti    train  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class id</th>\n      <th>filepaths</th>\n      <th>labels</th>\n      <th>scientific label</th>\n      <th>data set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>train/ABBOTTS BABBLER/001.jpg</td>\n      <td>ABBOTTS BABBLER</td>\n      <td>Malacocincla abbotti</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>train/ABBOTTS BABBLER/002.jpg</td>\n      <td>ABBOTTS BABBLER</td>\n      <td>Malacocincla abbotti</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>train/ABBOTTS BABBLER/003.jpg</td>\n      <td>ABBOTTS BABBLER</td>\n      <td>Malacocincla abbotti</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>train/ABBOTTS BABBLER/004.jpg</td>\n      <td>ABBOTTS BABBLER</td>\n      <td>Malacocincla abbotti</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>train/ABBOTTS BABBLER/005.jpg</td>\n      <td>ABBOTTS BABBLER</td>\n      <td>Malacocincla abbotti</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabulated_data = pd.read_csv('birds.csv')\n",
    "tabulated_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "tabulated_data.rename({'class id':'class_id'}, axis = 1, inplace=True)\n",
    "\n",
    "#Look for train/test data only\n",
    "tabulated_data = tabulated_data[(tabulated_data['data set'] == 'train')|(tabulated_data['data set'] == 'test')]\n",
    "#Reduce Classes for testing purpose\n",
    "filtered_data = tabulated_data[tabulated_data['class_id'].isin(range(0,10))]\n",
    "\n",
    "df = filtered_data.sample(frac = 0.1).reset_index(drop = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Set the device to run on\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Transformations to apply to images\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "#Passing split data through dictionary\n",
    "\n",
    "df_train = df[df['data set'] == 'train'].copy()\n",
    "df_test = df[df['data set'] == 'test'].copy()\n",
    "df_train = df_train[['filepaths','class_id']]\n",
    "df_test = df_test[['filepaths','class_id']]\n",
    "\n",
    "train_data = df_train.to_dict('list')\n",
    "test_data = df_test.to_dict('list')\n",
    "\n",
    "filepaths = [train_data['filepaths'] for data in train_data]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "# Create the datasets\n",
    "train_dataset = torchvision.datasets.ImageFolder(root = 'train', transform=transform)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset ImageFolder\n    Number of datapoints: 70626\n    Root location: train\n    StandardTransform\nTransform: Compose(\n               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n               ToTensor()\n               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n           )"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.Sub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[-1.4843, -1.4500, -1.4500,  ..., -1.2274, -1.2274, -1.1932],\n          [-1.4843, -1.4500, -1.4672,  ..., -1.1932, -1.2103, -1.2103],\n          [-1.4672, -1.4500, -1.4672,  ..., -1.1589, -1.1932, -1.2103],\n          ...,\n          [ 0.5193, -0.0116, -0.6281,  ..., -1.0904, -1.1075, -1.1418],\n          [-0.2684, -0.6623, -0.2171,  ..., -1.0904, -1.1075, -1.1418],\n          [ 0.0056,  0.6221,  1.0844,  ..., -1.0904, -1.0904, -1.1247]],\n \n         [[-0.9503, -0.9153, -0.9503,  ..., -0.6176, -0.6001, -0.5651],\n          [-0.9503, -0.9153, -0.9328,  ..., -0.5826, -0.5826, -0.5826],\n          [-0.9328, -0.9153, -0.9328,  ..., -0.5476, -0.5651, -0.5826],\n          ...,\n          [ 0.2227, -0.3550, -1.0728,  ..., -0.5126, -0.5476, -0.5826],\n          [-0.7052, -1.1253, -0.6877,  ..., -0.5126, -0.5476, -0.5826],\n          [-0.5126,  0.1527,  0.6254,  ..., -0.5126, -0.5301, -0.5651]],\n \n         [[-1.2293, -1.1944, -1.2119,  ..., -0.9330, -0.9678, -0.9330],\n          [-1.2293, -1.1944, -1.2119,  ..., -0.8981, -0.9504, -0.9504],\n          [-1.2119, -1.1944, -1.2119,  ..., -0.8633, -0.9330, -0.9504],\n          ...,\n          [ 0.0605, -0.4275, -1.0724,  ..., -0.4450, -0.4798, -0.5147],\n          [-0.7413, -1.0550, -0.4973,  ..., -0.4450, -0.4798, -0.5147],\n          [-0.4450,  0.3393,  0.9494,  ..., -0.4450, -0.4624, -0.4973]]]),\n 0)"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[ 1.2043,  1.1872,  1.1700,  ...,  1.0159,  1.0331,  1.0159],\n          [ 1.2043,  1.2043,  1.1872,  ...,  0.9817,  0.9988,  0.9817],\n          [ 1.2043,  1.2214,  1.2214,  ...,  0.9303,  0.9646,  0.9474],\n          ...,\n          [-0.4739, -0.2856, -0.7822,  ..., -0.1143, -0.2513,  0.1254],\n          [-0.2171, -0.8678, -0.9192,  ..., -0.7479, -0.1143, -0.1143],\n          [-0.9877, -1.0048, -1.3302,  ..., -0.0629,  0.2624, -0.3541]],\n \n         [[ 1.1856,  1.1681,  1.1506,  ...,  0.9930,  1.0105,  0.9930],\n          [ 1.1856,  1.1856,  1.1681,  ...,  0.9580,  0.9755,  0.9580],\n          [ 1.1856,  1.2031,  1.2031,  ...,  0.9055,  0.9405,  0.9230],\n          ...,\n          [-0.4951, -0.3200, -0.8627,  ...,  0.2927,  0.1352,  0.5903],\n          [-0.1975, -0.9328, -1.0028,  ..., -0.3725,  0.2577,  0.2752],\n          [-0.9853, -1.0203, -1.4405,  ...,  0.2927,  0.6254,  0.0301]],\n \n         [[ 0.9668,  0.9494,  0.9319,  ...,  0.2871,  0.3045,  0.3219],\n          [ 0.9668,  0.9668,  0.9494,  ...,  0.2522,  0.2696,  0.2871],\n          [ 0.9668,  0.9842,  0.9842,  ...,  0.1999,  0.2696,  0.2522],\n          ...,\n          [-0.8981, -0.6367, -1.0201,  ..., -1.0201, -1.1247, -0.7587],\n          [-0.5670, -1.1770, -1.0898,  ..., -1.7347, -1.0550, -1.0898],\n          [-1.3164, -1.2467, -1.4559,  ..., -1.0898, -0.7238, -1.3687]]]),\n 6)"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[999]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
